{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766b89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3cbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers\n",
    "#!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aed8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7eb10b",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78974f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f12244",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    use_fast=True  # Optional, but usually better performance\n",
    ")\n",
    "# Fix: set pad_token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f00cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8251d493ff4b40b44ac6d8d6ca0bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files='TrainingData.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32d7553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b6c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (80%), validation (10%), and test (10%)\n",
    "train_dataset = dataset['train'].train_test_split(test_size=0.2)  # 80% train, 20% test\n",
    "val_test_dataset = train_dataset['test'].train_test_split(test_size=0.5)  # Split the 20% into 50% validation and 50% test\n",
    "\n",
    "# Now you have train, validation, and test datasets\n",
    "train_dataset = train_dataset['train']\n",
    "validation_dataset = val_test_dataset['train']\n",
    "test_dataset = val_test_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d42ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ADD THIS LABEL MAPPING DICTIONARY -----\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-Disease\": 1,\n",
    "    \"I-Disease\": 2,\n",
    "    \"B-Medication\": 3,\n",
    "    \"I-Medication\": 4,\n",
    "    \"B-Person\": 5,\n",
    "    \"I-Person\": 6,\n",
    "    \"B-Location\": 7,\n",
    "    \"I-Location\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8c5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        [ [label['word'] for label in labels] for labels in examples['labels'] ], \n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=16\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "\n",
    "    for i, labels in enumerate(examples['labels']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                entity_label = labels[word_id]['entity']\n",
    "                label_ids.append(label2id.get(entity_label, 0))\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3660e8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e2cd4df796411fb3cd5de891db2839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The patient was diagnosed with type 2 diabetes and prescribed metformin.', 'labels': [-100, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 3, 3, 3], 'input_ids': [1, 415, 7749, 403, 26629, 395, 1212, 28705, 28750, 22794, 304, 20791, 13284, 1424, 674, 262], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Apply the tokenization and label alignment to the entire dataset\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "# You can check if everything is correct by inspecting a sample\n",
    "print(tokenized_datasets['train'][0])  # Print the first example of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7c1c2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 52\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41eb90c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e9bd54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed1beb5d2d94226afa6d136bccee31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae8f41d2bf7404c916b90a0b90dfe36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625ebcbc7aef4a498913e214a83fdbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Michael Brown experienced severe headaches due to hypertension.', 'labels': [-100, -100, -100, -100, 5, 6, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 'input_ids': [2, 2, 2, 1, 5459, 8364, 8304, 13645, 1335, 5131, 2940, 298, 6521, 2482, 2585, 842], 'attention_mask': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Apply tokenization and label alignment to dataset splits\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "validation_dataset = validation_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Optional: inspect one sample to verify\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb81d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 415, 7749, 403, 26629, 395, 1212, 28705, 28750, 22794, 304, 20791, 13284, 1424, 674, 262]\n",
      "16\n",
      "[-100, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 3, 3, 3]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['train'][0]['input_ids'])\n",
    "print(len(tokenized_datasets['train'][0]['input_ids']))  # Should be 16\n",
    "\n",
    "print(tokenized_datasets['train'][0]['labels'])\n",
    "print(len(tokenized_datasets['train'][0]['labels']))  # Should also be 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7825d",
   "metadata": {},
   "source": [
    "### Model Loading, Qunatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f10375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ffd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a869ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure quantization for QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16  # fallback to float16 for broader support\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4c76e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e796aed097434cb8b02a9fe25c3eb09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForTokenClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.1 and are newly initialized: ['score.bias', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model with quantization (this makes it QLoRA)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    quantization_config=bnb_config,  # This enables quantization\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    num_labels=len(label2id )  # Set your number of NER labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052559b2",
   "metadata": {},
   "source": [
    "### Checking the whether model is Quantized successully or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c706ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: model.embed_tokens.weight\n",
      "Data type: torch.float16\n",
      "Shape: torch.Size([32000, 4096])\n",
      "First few values: tensor([-0., 0., -0., 0., 0.], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Check dtype of first parameter\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}\")\n",
    "    print(f\"Data type: {param.dtype}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"First few values: {param.data.flatten()[:5]}\")\n",
    "    break  # Just show first parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6640806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 3.6002368927001953 GB\n",
      "Memory cached: 3.83203125 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024**3} GB\")\n",
    "print(f\"Memory cached: {torch.cuda.memory_reserved() / 1024**3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3626556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer model.layers.0.self_attn.q_proj is of type Linear4bit\n",
      "Data type: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):  # Check if any linear layers are quantized\n",
    "        print(f\"Layer {name} is of type {module.__class__.__name__}\")\n",
    "        print(f\"Data type: {module.weight.dtype}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88ac0a",
   "metadata": {},
   "source": [
    "Based on the Linear4bit type and the torch.uint8 data type, it is clear that the model has been successfully quantized, specifically with 4-bit precision for some of the layers (such as the query projection in the attention mechanism, i.e., q_proj). The memory usage is also consistent with this, as quantization reduces memory requirements.\n",
    "\n",
    "Thus, your model is quantized and working as expected, with specific layers like attention heads (query projection) using 4-bit precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b6f49",
   "metadata": {},
   "source": [
    "### 🔧 Importance of `prepare_model_for_kbit_training(model)`\n",
    "\n",
    "This line is **essential when using quantized models (4-bit / 8-bit)** with LoRA or QLoRA fine-tuning.\n",
    "\n",
    "#### ✅ What it does:\n",
    "\n",
    "- Ensures **gradient flow** from inputs to LoRA layers (needed for learning).\n",
    "- Converts sensitive layers (like LayerNorm) to **float32** for stability.\n",
    "- Prepares the model for **adapter-based training** (e.g., LoRA).\n",
    "- Makes the quantized model compatible with **PEFT (Parameter-Efficient Fine-Tuning)**.\n",
    "\n",
    "#### 🤔 Why it's important:\n",
    "\n",
    "- Without this line, **LoRA layers may not get updated** (no learning).\n",
    "- Training may become **unstable or ineffective**.\n",
    "- Essential step to make quantized models **trainable**.\n",
    "\n",
    "#### 📌 When to use it:\n",
    "\n",
    "- After loading a model in **4-bit / 8-bit precision** using `BitsAndBytesConfig`.\n",
    "- Before applying **LoRA adapters** using `get_peft_model()`.\n",
    "\n",
    "#### 💡 Example usage:\n",
    "\n",
    "```python\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "# Step: Prepare quantized model for training\n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35746416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba96cff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForTokenClassification(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (score): Linear(in_features=4096, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8fdf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA (same as before, but now applied to quantized model)\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # rank\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Mistral uses these names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"TOKEN_CLS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e01b9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d19474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,852,617 || all params: 7,117,549,586 || trainable%: 0.0963\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a5ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments remain the same\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,  # Often needs to be slightly higher for QLoRA\n",
    "    per_device_train_batch_size=10,  # May need to reduce due to quantization overhead\n",
    "    per_device_eval_batch_size=10,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=5,  # log every step\n",
    "    gradient_checkpointing=True,  # Helps save memory\n",
    "    fp16=True,  # Mixed precision training\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d131a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bbef950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 00:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.944300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.310700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=0.46627191702524823, metrics={'train_runtime': 25.7452, 'train_samples_per_second': 6.059, 'train_steps_per_second': 0.699, 'total_flos': 104629488327936.0, 'train_loss': 0.46627191702524823, 'epoch': 3.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9fff81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004685596562922001, 'eval_runtime': 0.5449, 'eval_samples_per_second': 9.176, 'eval_steps_per_second': 1.835, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(eval_dataset=validation_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01824a02",
   "metadata": {},
   "source": [
    "🔍 Fine-tuning Summary (Epoch 3)\n",
    "────────────────────────────────────────────────────────\n",
    "\n",
    "📉 Training Loss:\n",
    "   → 0.4662\n",
    "   This is low and suggests the model has learned the training data well.\n",
    "\n",
    "🧪 Evaluation Loss:\n",
    "   → 0.0046\n",
    "   A very low eval loss, indicating strong generalization to unseen data.\n",
    "\n",
    "⚙️ Training Metrics:\n",
    "   - Epochs completed: 3\n",
    "   - Global steps: 18\n",
    "   - Training runtime: 25.74s\n",
    "   - Samples/sec: 6.059\n",
    "   - Steps/sec: 0.69\n",
    "\n",
    "📊 Evaluation Metrics:\n",
    "   - Runtime: 0.5449s\n",
    "   - Eval samples/sec: 9.176\n",
    "   - Eval steps/sec: 1.835\n",
    "\n",
    "✅ Key Takeaways:\n",
    "────────────────────────────────────────────────────────\n",
    "- ✔️ Training and evaluation losses are both low — this is a strong sign that:\n",
    "    - The model is **learning the task well**.\n",
    "    - There’s **no sign of overfitting** (low train and eval loss).\n",
    "    - Your **data preprocessing and token-label alignment** are likely working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92e7fe",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0c954b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your labels in order\n",
    "labels = [\n",
    "    \"O\",\n",
    "    \"B-Disease\",\n",
    "    \"I-Disease\",\n",
    "    \"B-Medication\",\n",
    "    \"I-Medication\",\n",
    "    \"B-Person\",\n",
    "    \"I-Person\",\n",
    "    \"B-Location\",\n",
    "    \"I-Location\"\n",
    "]\n",
    "\n",
    "# Create label ↔ ID mappings\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2690990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-Disease',\n",
       " 2: 'I-Disease',\n",
       " 3: 'B-Medication',\n",
       " 4: 'I-Medication',\n",
       " 5: 'B-Person',\n",
       " 6: 'I-Person',\n",
       " 7: 'B-Location',\n",
       " 8: 'I-Location'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "430879fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"ner\",\n",
    "    model=trainer.model,       # No need to reload\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d2cb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateNER(text,pipeline,id2label):\n",
    "    output = ner_pipeline(text)\n",
    "    for entity in output:\n",
    "        label_id = int(entity['entity_group'].split(\"_\")[-1])\n",
    "        print(f\"{entity['word']} -> {id2label[label_id]} ({entity['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80cab589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. -> B-Person (1.00)\n",
      "John -> I-Person (1.00)\n",
      "gave am -> O (0.95)\n",
      "oxicillin -> B-Medication (1.00)\n",
      "for severe -> O (0.82)\n",
      "pneum -> B-Disease (1.00)\n",
      "onia -> I-Disease (0.99)\n",
      ". -> O (1.00)\n"
     ]
    }
   ],
   "source": [
    "text = \"Dr. John gave amoxicillin for severe pneumonia.\"\n",
    "GenerateNER(text,pipeline,id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c9f53c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d2c1d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1a099dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8107, Recall: 0.8358, F1: 0.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amank\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Get predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Get the predicted and true labels\n",
    "y_pred = predictions.predictions.argmax(axis=-1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Flatten predictions and labels, skipping padding tokens (-100)\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for pred, true in zip(y_pred, y_true):\n",
    "    for p, t in zip(pred, true):\n",
    "        if t != -100:\n",
    "            true_labels.append(t)\n",
    "            pred_labels.append(p)\n",
    "\n",
    "# Compute precision, recall, and F1\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10ecec",
   "metadata": {},
   "source": [
    "## Random New Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ba640a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [\n",
    "  {\n",
    "    \"text\": \"Michael Johnson was treated with paracetamol at Mercy Hospital.\",\n",
    "    \"labels\": [\n",
    "      {\"word\": \"Michael\", \"entity\": \"B-Person\"},\n",
    "      {\"word\": \"Johnson\", \"entity\": \"I-Person\"},\n",
    "      {\"word\": \"was\", \"entity\": \"O\"},\n",
    "      {\"word\": \"treated\", \"entity\": \"O\"},\n",
    "      {\"word\": \"with\", \"entity\": \"O\"},\n",
    "      {\"word\": \"paracetamol\", \"entity\": \"B-Medication\"},\n",
    "      {\"word\": \"at\", \"entity\": \"O\"},\n",
    "      {\"word\": \"Mercy\", \"entity\": \"B-Location\"},\n",
    "      {\"word\": \"Hospital\", \"entity\": \"I-Location\"},\n",
    "      {\"word\": \".\", \"entity\": \"O\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"text\": \"She was diagnosed with COVID 19 and given remdesivir.\",\n",
    "    \"labels\": [\n",
    "      {\"word\": \"She\", \"entity\": \"O\"},\n",
    "      {\"word\": \"was\", \"entity\": \"O\"},\n",
    "      {\"word\": \"diagnosed\", \"entity\": \"O\"},\n",
    "      {\"word\": \"with\", \"entity\": \"O\"},\n",
    "      {\"word\": \"COVID\", \"entity\": \"B-Disease\"},\n",
    "      {\"word\": \"19\", \"entity\": \"I-Disease\"},\n",
    "      {\"word\": \"and\", \"entity\": \"O\"},\n",
    "      {\"word\": \"given\", \"entity\": \"O\"},\n",
    "      {\"word\": \"remdesivir\", \"entity\": \"B-Medication\"},\n",
    "      {\"word\": \".\", \"entity\": \"O\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"text\": \"The patient complained of chest pain and was given nitroglycerin.\",\n",
    "    \"labels\": [\n",
    "      {\"word\": \"The\", \"entity\": \"O\"},\n",
    "      {\"word\": \"patient\", \"entity\": \"O\"},\n",
    "      {\"word\": \"complained\", \"entity\": \"O\"},\n",
    "      {\"word\": \"of\", \"entity\": \"O\"},\n",
    "      {\"word\": \"chest\", \"entity\": \"B-Disease\"},\n",
    "      {\"word\": \"pain\", \"entity\": \"I-Disease\"},\n",
    "      {\"word\": \"and\", \"entity\": \"O\"},\n",
    "      {\"word\": \"was\", \"entity\": \"O\"},\n",
    "      {\"word\": \"given\", \"entity\": \"O\"},\n",
    "      {\"word\": \"nitroglycerin\", \"entity\": \"B-Medication\"},\n",
    "      {\"word\": \".\", \"entity\": \"O\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"text\": \"Dr. Laura White reviewed the MRI scan for spinal injury.\",\n",
    "    \"labels\": [\n",
    "      {\"word\": \"Dr.\", \"entity\": \"B-Person\"},\n",
    "      {\"word\": \"Laura\", \"entity\": \"I-Person\"},\n",
    "      {\"word\": \"White\", \"entity\": \"I-Person\"},\n",
    "      {\"word\": \"reviewed\", \"entity\": \"O\"},\n",
    "      {\"word\": \"the\", \"entity\": \"O\"},\n",
    "      {\"word\": \"MRI\", \"entity\": \"O\"},\n",
    "      {\"word\": \"scan\", \"entity\": \"O\"},\n",
    "      {\"word\": \"for\", \"entity\": \"O\"},\n",
    "      {\"word\": \"spinal\", \"entity\": \"B-Disease\"},\n",
    "      {\"word\": \"injury\", \"entity\": \"I-Disease\"},\n",
    "      {\"word\": \".\", \"entity\": \"O\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"text\": \"They visited Stanford Medical Center for surgery.\",\n",
    "    \"labels\": [\n",
    "      {\"word\": \"They\", \"entity\": \"O\"},\n",
    "      {\"word\": \"visited\", \"entity\": \"O\"},\n",
    "      {\"word\": \"Stanford\", \"entity\": \"B-Location\"},\n",
    "      {\"word\": \"Medical\", \"entity\": \"I-Location\"},\n",
    "      {\"word\": \"Center\", \"entity\": \"I-Location\"},\n",
    "      {\"word\": \"for\", \"entity\": \"O\"},\n",
    "      {\"word\": \"surgery\", \"entity\": \"O\"},\n",
    "      {\"word\": \".\", \"entity\": \"O\"}\n",
    "    ]\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1507a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create Dataset from list\n",
    "dataset = Dataset.from_list(sample_data)\n",
    "\n",
    "# Check\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1538f22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85632a204f94739b6d09d081dee00fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deeee68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "983512d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8107, Recall: 0.8358, F1: 0.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amank\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Get predictions on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Get the predicted and true labels\n",
    "y_pred = predictions.predictions.argmax(axis=-1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Flatten predictions and labels, skipping padding tokens (-100)\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for pred, true in zip(y_pred, y_true):\n",
    "    for p, t in zip(pred, true):\n",
    "        if t != -100:\n",
    "            true_labels.append(t)\n",
    "            pred_labels.append(p)\n",
    "\n",
    "# Compute precision, recall, and F1\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ca1e6",
   "metadata": {},
   "source": [
    "## Pushing model to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "856bf875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\amank\\anaconda3\\lib\\site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amank\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amank\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad9c9d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94c50279bed48e283bffb0a9d3ef464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e972fa671f4a10a78bb16ccb49a8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Aghori/mistral-medical-ner-qlora/commit/42dcca8720e53a3a01d2e801bbbd9d8f7483f6a8', commit_message='Upload model', commit_description='', oid='42dcca8720e53a3a01d2e801bbbd9d8f7483f6a8', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Aghori/mistral-medical-ner-qlora', endpoint='https://huggingface.co', repo_type='model', repo_id='Aghori/mistral-medical-ner-qlora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()  # Or CLI login\n",
    "\n",
    "peft_model.push_to_hub(\"Aghori/mistral-medical-ner-qlora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50d00d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef13c16b8f534fc1bb5c21bc238d6c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amank\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\amank\\.cache\\huggingface\\hub\\models--Aghori--mistral-medical-ner-qlora. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fd44c1837d4bee839d97d39c56e724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec377a535984c4880188155ff915907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/27.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from Aghori/mistral-medical-ner-qlora led to unexpected keys not found in the model: model.layers.0.self_attn.k_proj.lora_A.default.weight, model.layers.0.self_attn.k_proj.lora_B.default.weight, model.layers.0.self_attn.o_proj.lora_A.default.weight, model.layers.0.self_attn.o_proj.lora_B.default.weight, model.layers.0.self_attn.q_proj.lora_A.default.weight, model.layers.0.self_attn.q_proj.lora_B.default.weight, model.layers.0.self_attn.v_proj.lora_A.default.weight, model.layers.0.self_attn.v_proj.lora_B.default.weight, model.layers.1.self_attn.k_proj.lora_A.default.weight, model.layers.1.self_attn.k_proj.lora_B.default.weight, model.layers.1.self_attn.o_proj.lora_A.default.weight, model.layers.1.self_attn.o_proj.lora_B.default.weight, model.layers.1.self_attn.q_proj.lora_A.default.weight, model.layers.1.self_attn.q_proj.lora_B.default.weight, model.layers.1.self_attn.v_proj.lora_A.default.weight, model.layers.1.self_attn.v_proj.lora_B.default.weight, model.layers.10.self_attn.k_proj.lora_A.default.weight, model.layers.10.self_attn.k_proj.lora_B.default.weight, model.layers.10.self_attn.o_proj.lora_A.default.weight, model.layers.10.self_attn.o_proj.lora_B.default.weight, model.layers.10.self_attn.q_proj.lora_A.default.weight, model.layers.10.self_attn.q_proj.lora_B.default.weight, model.layers.10.self_attn.v_proj.lora_A.default.weight, model.layers.10.self_attn.v_proj.lora_B.default.weight, model.layers.11.self_attn.k_proj.lora_A.default.weight, model.layers.11.self_attn.k_proj.lora_B.default.weight, model.layers.11.self_attn.o_proj.lora_A.default.weight, model.layers.11.self_attn.o_proj.lora_B.default.weight, model.layers.11.self_attn.q_proj.lora_A.default.weight, model.layers.11.self_attn.q_proj.lora_B.default.weight, model.layers.11.self_attn.v_proj.lora_A.default.weight, model.layers.11.self_attn.v_proj.lora_B.default.weight, model.layers.12.self_attn.k_proj.lora_A.default.weight, model.layers.12.self_attn.k_proj.lora_B.default.weight, model.layers.12.self_attn.o_proj.lora_A.default.weight, model.layers.12.self_attn.o_proj.lora_B.default.weight, model.layers.12.self_attn.q_proj.lora_A.default.weight, model.layers.12.self_attn.q_proj.lora_B.default.weight, model.layers.12.self_attn.v_proj.lora_A.default.weight, model.layers.12.self_attn.v_proj.lora_B.default.weight, model.layers.13.self_attn.k_proj.lora_A.default.weight, model.layers.13.self_attn.k_proj.lora_B.default.weight, model.layers.13.self_attn.o_proj.lora_A.default.weight, model.layers.13.self_attn.o_proj.lora_B.default.weight, model.layers.13.self_attn.q_proj.lora_A.default.weight, model.layers.13.self_attn.q_proj.lora_B.default.weight, model.layers.13.self_attn.v_proj.lora_A.default.weight, model.layers.13.self_attn.v_proj.lora_B.default.weight, model.layers.14.self_attn.k_proj.lora_A.default.weight, model.layers.14.self_attn.k_proj.lora_B.default.weight, model.layers.14.self_attn.o_proj.lora_A.default.weight, model.layers.14.self_attn.o_proj.lora_B.default.weight, model.layers.14.self_attn.q_proj.lora_A.default.weight, model.layers.14.self_attn.q_proj.lora_B.default.weight, model.layers.14.self_attn.v_proj.lora_A.default.weight, model.layers.14.self_attn.v_proj.lora_B.default.weight, model.layers.15.self_attn.k_proj.lora_A.default.weight, model.layers.15.self_attn.k_proj.lora_B.default.weight, model.layers.15.self_attn.o_proj.lora_A.default.weight, model.layers.15.self_attn.o_proj.lora_B.default.weight, model.layers.15.self_attn.q_proj.lora_A.default.weight, model.layers.15.self_attn.q_proj.lora_B.default.weight, model.layers.15.self_attn.v_proj.lora_A.default.weight, model.layers.15.self_attn.v_proj.lora_B.default.weight, model.layers.16.self_attn.k_proj.lora_A.default.weight, model.layers.16.self_attn.k_proj.lora_B.default.weight, model.layers.16.self_attn.o_proj.lora_A.default.weight, model.layers.16.self_attn.o_proj.lora_B.default.weight, model.layers.16.self_attn.q_proj.lora_A.default.weight, model.layers.16.self_attn.q_proj.lora_B.default.weight, model.layers.16.self_attn.v_proj.lora_A.default.weight, model.layers.16.self_attn.v_proj.lora_B.default.weight, model.layers.17.self_attn.k_proj.lora_A.default.weight, model.layers.17.self_attn.k_proj.lora_B.default.weight, model.layers.17.self_attn.o_proj.lora_A.default.weight, model.layers.17.self_attn.o_proj.lora_B.default.weight, model.layers.17.self_attn.q_proj.lora_A.default.weight, model.layers.17.self_attn.q_proj.lora_B.default.weight, model.layers.17.self_attn.v_proj.lora_A.default.weight, model.layers.17.self_attn.v_proj.lora_B.default.weight, model.layers.18.self_attn.k_proj.lora_A.default.weight, model.layers.18.self_attn.k_proj.lora_B.default.weight, model.layers.18.self_attn.o_proj.lora_A.default.weight, model.layers.18.self_attn.o_proj.lora_B.default.weight, model.layers.18.self_attn.q_proj.lora_A.default.weight, model.layers.18.self_attn.q_proj.lora_B.default.weight, model.layers.18.self_attn.v_proj.lora_A.default.weight, model.layers.18.self_attn.v_proj.lora_B.default.weight, model.layers.19.self_attn.k_proj.lora_A.default.weight, model.layers.19.self_attn.k_proj.lora_B.default.weight, model.layers.19.self_attn.o_proj.lora_A.default.weight, model.layers.19.self_attn.o_proj.lora_B.default.weight, model.layers.19.self_attn.q_proj.lora_A.default.weight, model.layers.19.self_attn.q_proj.lora_B.default.weight, model.layers.19.self_attn.v_proj.lora_A.default.weight, model.layers.19.self_attn.v_proj.lora_B.default.weight, model.layers.2.self_attn.k_proj.lora_A.default.weight, model.layers.2.self_attn.k_proj.lora_B.default.weight, model.layers.2.self_attn.o_proj.lora_A.default.weight, model.layers.2.self_attn.o_proj.lora_B.default.weight, model.layers.2.self_attn.q_proj.lora_A.default.weight, model.layers.2.self_attn.q_proj.lora_B.default.weight, model.layers.2.self_attn.v_proj.lora_A.default.weight, model.layers.2.self_attn.v_proj.lora_B.default.weight, model.layers.20.self_attn.k_proj.lora_A.default.weight, model.layers.20.self_attn.k_proj.lora_B.default.weight, model.layers.20.self_attn.o_proj.lora_A.default.weight, model.layers.20.self_attn.o_proj.lora_B.default.weight, model.layers.20.self_attn.q_proj.lora_A.default.weight, model.layers.20.self_attn.q_proj.lora_B.default.weight, model.layers.20.self_attn.v_proj.lora_A.default.weight, model.layers.20.self_attn.v_proj.lora_B.default.weight, model.layers.21.self_attn.k_proj.lora_A.default.weight, model.layers.21.self_attn.k_proj.lora_B.default.weight, model.layers.21.self_attn.o_proj.lora_A.default.weight, model.layers.21.self_attn.o_proj.lora_B.default.weight, model.layers.21.self_attn.q_proj.lora_A.default.weight, model.layers.21.self_attn.q_proj.lora_B.default.weight, model.layers.21.self_attn.v_proj.lora_A.default.weight, model.layers.21.self_attn.v_proj.lora_B.default.weight, model.layers.22.self_attn.k_proj.lora_A.default.weight, model.layers.22.self_attn.k_proj.lora_B.default.weight, model.layers.22.self_attn.o_proj.lora_A.default.weight, model.layers.22.self_attn.o_proj.lora_B.default.weight, model.layers.22.self_attn.q_proj.lora_A.default.weight, model.layers.22.self_attn.q_proj.lora_B.default.weight, model.layers.22.self_attn.v_proj.lora_A.default.weight, model.layers.22.self_attn.v_proj.lora_B.default.weight, model.layers.23.self_attn.k_proj.lora_A.default.weight, model.layers.23.self_attn.k_proj.lora_B.default.weight, model.layers.23.self_attn.o_proj.lora_A.default.weight, model.layers.23.self_attn.o_proj.lora_B.default.weight, model.layers.23.self_attn.q_proj.lora_A.default.weight, model.layers.23.self_attn.q_proj.lora_B.default.weight, model.layers.23.self_attn.v_proj.lora_A.default.weight, model.layers.23.self_attn.v_proj.lora_B.default.weight, model.layers.24.self_attn.k_proj.lora_A.default.weight, model.layers.24.self_attn.k_proj.lora_B.default.weight, model.layers.24.self_attn.o_proj.lora_A.default.weight, model.layers.24.self_attn.o_proj.lora_B.default.weight, model.layers.24.self_attn.q_proj.lora_A.default.weight, model.layers.24.self_attn.q_proj.lora_B.default.weight, model.layers.24.self_attn.v_proj.lora_A.default.weight, model.layers.24.self_attn.v_proj.lora_B.default.weight, model.layers.25.self_attn.k_proj.lora_A.default.weight, model.layers.25.self_attn.k_proj.lora_B.default.weight, model.layers.25.self_attn.o_proj.lora_A.default.weight, model.layers.25.self_attn.o_proj.lora_B.default.weight, model.layers.25.self_attn.q_proj.lora_A.default.weight, model.layers.25.self_attn.q_proj.lora_B.default.weight, model.layers.25.self_attn.v_proj.lora_A.default.weight, model.layers.25.self_attn.v_proj.lora_B.default.weight, model.layers.26.self_attn.k_proj.lora_A.default.weight, model.layers.26.self_attn.k_proj.lora_B.default.weight, model.layers.26.self_attn.o_proj.lora_A.default.weight, model.layers.26.self_attn.o_proj.lora_B.default.weight, model.layers.26.self_attn.q_proj.lora_A.default.weight, model.layers.26.self_attn.q_proj.lora_B.default.weight, model.layers.26.self_attn.v_proj.lora_A.default.weight, model.layers.26.self_attn.v_proj.lora_B.default.weight, model.layers.27.self_attn.k_proj.lora_A.default.weight, model.layers.27.self_attn.k_proj.lora_B.default.weight, model.layers.27.self_attn.o_proj.lora_A.default.weight, model.layers.27.self_attn.o_proj.lora_B.default.weight, model.layers.27.self_attn.q_proj.lora_A.default.weight, model.layers.27.self_attn.q_proj.lora_B.default.weight, model.layers.27.self_attn.v_proj.lora_A.default.weight, model.layers.27.self_attn.v_proj.lora_B.default.weight, model.layers.28.self_attn.k_proj.lora_A.default.weight, model.layers.28.self_attn.k_proj.lora_B.default.weight, model.layers.28.self_attn.o_proj.lora_A.default.weight, model.layers.28.self_attn.o_proj.lora_B.default.weight, model.layers.28.self_attn.q_proj.lora_A.default.weight, model.layers.28.self_attn.q_proj.lora_B.default.weight, model.layers.28.self_attn.v_proj.lora_A.default.weight, model.layers.28.self_attn.v_proj.lora_B.default.weight, model.layers.29.self_attn.k_proj.lora_A.default.weight, model.layers.29.self_attn.k_proj.lora_B.default.weight, model.layers.29.self_attn.o_proj.lora_A.default.weight, model.layers.29.self_attn.o_proj.lora_B.default.weight, model.layers.29.self_attn.q_proj.lora_A.default.weight, model.layers.29.self_attn.q_proj.lora_B.default.weight, model.layers.29.self_attn.v_proj.lora_A.default.weight, model.layers.29.self_attn.v_proj.lora_B.default.weight, model.layers.3.self_attn.k_proj.lora_A.default.weight, model.layers.3.self_attn.k_proj.lora_B.default.weight, model.layers.3.self_attn.o_proj.lora_A.default.weight, model.layers.3.self_attn.o_proj.lora_B.default.weight, model.layers.3.self_attn.q_proj.lora_A.default.weight, model.layers.3.self_attn.q_proj.lora_B.default.weight, model.layers.3.self_attn.v_proj.lora_A.default.weight, model.layers.3.self_attn.v_proj.lora_B.default.weight, model.layers.30.self_attn.k_proj.lora_A.default.weight, model.layers.30.self_attn.k_proj.lora_B.default.weight, model.layers.30.self_attn.o_proj.lora_A.default.weight, model.layers.30.self_attn.o_proj.lora_B.default.weight, model.layers.30.self_attn.q_proj.lora_A.default.weight, model.layers.30.self_attn.q_proj.lora_B.default.weight, model.layers.30.self_attn.v_proj.lora_A.default.weight, model.layers.30.self_attn.v_proj.lora_B.default.weight, model.layers.31.self_attn.k_proj.lora_A.default.weight, model.layers.31.self_attn.k_proj.lora_B.default.weight, model.layers.31.self_attn.o_proj.lora_A.default.weight, model.layers.31.self_attn.o_proj.lora_B.default.weight, model.layers.31.self_attn.q_proj.lora_A.default.weight, model.layers.31.self_attn.q_proj.lora_B.default.weight, model.layers.31.self_attn.v_proj.lora_A.default.weight, model.layers.31.self_attn.v_proj.lora_B.default.weight, model.layers.4.self_attn.k_proj.lora_A.default.weight, model.layers.4.self_attn.k_proj.lora_B.default.weight, model.layers.4.self_attn.o_proj.lora_A.default.weight, model.layers.4.self_attn.o_proj.lora_B.default.weight, model.layers.4.self_attn.q_proj.lora_A.default.weight, model.layers.4.self_attn.q_proj.lora_B.default.weight, model.layers.4.self_attn.v_proj.lora_A.default.weight, model.layers.4.self_attn.v_proj.lora_B.default.weight, model.layers.5.self_attn.k_proj.lora_A.default.weight, model.layers.5.self_attn.k_proj.lora_B.default.weight, model.layers.5.self_attn.o_proj.lora_A.default.weight, model.layers.5.self_attn.o_proj.lora_B.default.weight, model.layers.5.self_attn.q_proj.lora_A.default.weight, model.layers.5.self_attn.q_proj.lora_B.default.weight, model.layers.5.self_attn.v_proj.lora_A.default.weight, model.layers.5.self_attn.v_proj.lora_B.default.weight, model.layers.6.self_attn.k_proj.lora_A.default.weight, model.layers.6.self_attn.k_proj.lora_B.default.weight, model.layers.6.self_attn.o_proj.lora_A.default.weight, model.layers.6.self_attn.o_proj.lora_B.default.weight, model.layers.6.self_attn.q_proj.lora_A.default.weight, model.layers.6.self_attn.q_proj.lora_B.default.weight, model.layers.6.self_attn.v_proj.lora_A.default.weight, model.layers.6.self_attn.v_proj.lora_B.default.weight, model.layers.7.self_attn.k_proj.lora_A.default.weight, model.layers.7.self_attn.k_proj.lora_B.default.weight, model.layers.7.self_attn.o_proj.lora_A.default.weight, model.layers.7.self_attn.o_proj.lora_B.default.weight, model.layers.7.self_attn.q_proj.lora_A.default.weight, model.layers.7.self_attn.q_proj.lora_B.default.weight, model.layers.7.self_attn.v_proj.lora_A.default.weight, model.layers.7.self_attn.v_proj.lora_B.default.weight, model.layers.8.self_attn.k_proj.lora_A.default.weight, model.layers.8.self_attn.k_proj.lora_B.default.weight, model.layers.8.self_attn.o_proj.lora_A.default.weight, model.layers.8.self_attn.o_proj.lora_B.default.weight, model.layers.8.self_attn.q_proj.lora_A.default.weight, model.layers.8.self_attn.q_proj.lora_B.default.weight, model.layers.8.self_attn.v_proj.lora_A.default.weight, model.layers.8.self_attn.v_proj.lora_B.default.weight, model.layers.9.self_attn.k_proj.lora_A.default.weight, model.layers.9.self_attn.k_proj.lora_B.default.weight, model.layers.9.self_attn.o_proj.lora_A.default.weight, model.layers.9.self_attn.o_proj.lora_B.default.weight, model.layers.9.self_attn.q_proj.lora_A.default.weight, model.layers.9.self_attn.q_proj.lora_B.default.weight, model.layers.9.self_attn.v_proj.lora_A.default.weight, model.layers.9.self_attn.v_proj.lora_B.default.weight, score.bias, score.weight. Loading adapter weights from Aghori/mistral-medical-ner-qlora led to missing keys in the model: layers.0.self_attn.q_proj.lora_A.default.weight, layers.0.self_attn.q_proj.lora_B.default.weight, layers.0.self_attn.k_proj.lora_A.default.weight, layers.0.self_attn.k_proj.lora_B.default.weight, layers.0.self_attn.v_proj.lora_A.default.weight, layers.0.self_attn.v_proj.lora_B.default.weight, layers.0.self_attn.o_proj.lora_A.default.weight, layers.0.self_attn.o_proj.lora_B.default.weight, layers.1.self_attn.q_proj.lora_A.default.weight, layers.1.self_attn.q_proj.lora_B.default.weight, layers.1.self_attn.k_proj.lora_A.default.weight, layers.1.self_attn.k_proj.lora_B.default.weight, layers.1.self_attn.v_proj.lora_A.default.weight, layers.1.self_attn.v_proj.lora_B.default.weight, layers.1.self_attn.o_proj.lora_A.default.weight, layers.1.self_attn.o_proj.lora_B.default.weight, layers.2.self_attn.q_proj.lora_A.default.weight, layers.2.self_attn.q_proj.lora_B.default.weight, layers.2.self_attn.k_proj.lora_A.default.weight, layers.2.self_attn.k_proj.lora_B.default.weight, layers.2.self_attn.v_proj.lora_A.default.weight, layers.2.self_attn.v_proj.lora_B.default.weight, layers.2.self_attn.o_proj.lora_A.default.weight, layers.2.self_attn.o_proj.lora_B.default.weight, layers.3.self_attn.q_proj.lora_A.default.weight, layers.3.self_attn.q_proj.lora_B.default.weight, layers.3.self_attn.k_proj.lora_A.default.weight, layers.3.self_attn.k_proj.lora_B.default.weight, layers.3.self_attn.v_proj.lora_A.default.weight, layers.3.self_attn.v_proj.lora_B.default.weight, layers.3.self_attn.o_proj.lora_A.default.weight, layers.3.self_attn.o_proj.lora_B.default.weight, layers.4.self_attn.q_proj.lora_A.default.weight, layers.4.self_attn.q_proj.lora_B.default.weight, layers.4.self_attn.k_proj.lora_A.default.weight, layers.4.self_attn.k_proj.lora_B.default.weight, layers.4.self_attn.v_proj.lora_A.default.weight, layers.4.self_attn.v_proj.lora_B.default.weight, layers.4.self_attn.o_proj.lora_A.default.weight, layers.4.self_attn.o_proj.lora_B.default.weight, layers.5.self_attn.q_proj.lora_A.default.weight, layers.5.self_attn.q_proj.lora_B.default.weight, layers.5.self_attn.k_proj.lora_A.default.weight, layers.5.self_attn.k_proj.lora_B.default.weight, layers.5.self_attn.v_proj.lora_A.default.weight, layers.5.self_attn.v_proj.lora_B.default.weight, layers.5.self_attn.o_proj.lora_A.default.weight, layers.5.self_attn.o_proj.lora_B.default.weight, layers.6.self_attn.q_proj.lora_A.default.weight, layers.6.self_attn.q_proj.lora_B.default.weight, layers.6.self_attn.k_proj.lora_A.default.weight, layers.6.self_attn.k_proj.lora_B.default.weight, layers.6.self_attn.v_proj.lora_A.default.weight, layers.6.self_attn.v_proj.lora_B.default.weight, layers.6.self_attn.o_proj.lora_A.default.weight, layers.6.self_attn.o_proj.lora_B.default.weight, layers.7.self_attn.q_proj.lora_A.default.weight, layers.7.self_attn.q_proj.lora_B.default.weight, layers.7.self_attn.k_proj.lora_A.default.weight, layers.7.self_attn.k_proj.lora_B.default.weight, layers.7.self_attn.v_proj.lora_A.default.weight, layers.7.self_attn.v_proj.lora_B.default.weight, layers.7.self_attn.o_proj.lora_A.default.weight, layers.7.self_attn.o_proj.lora_B.default.weight, layers.8.self_attn.q_proj.lora_A.default.weight, layers.8.self_attn.q_proj.lora_B.default.weight, layers.8.self_attn.k_proj.lora_A.default.weight, layers.8.self_attn.k_proj.lora_B.default.weight, layers.8.self_attn.v_proj.lora_A.default.weight, layers.8.self_attn.v_proj.lora_B.default.weight, layers.8.self_attn.o_proj.lora_A.default.weight, layers.8.self_attn.o_proj.lora_B.default.weight, layers.9.self_attn.q_proj.lora_A.default.weight, layers.9.self_attn.q_proj.lora_B.default.weight, layers.9.self_attn.k_proj.lora_A.default.weight, layers.9.self_attn.k_proj.lora_B.default.weight, layers.9.self_attn.v_proj.lora_A.default.weight, layers.9.self_attn.v_proj.lora_B.default.weight, layers.9.self_attn.o_proj.lora_A.default.weight, layers.9.self_attn.o_proj.lora_B.default.weight, layers.10.self_attn.q_proj.lora_A.default.weight, layers.10.self_attn.q_proj.lora_B.default.weight, layers.10.self_attn.k_proj.lora_A.default.weight, layers.10.self_attn.k_proj.lora_B.default.weight, layers.10.self_attn.v_proj.lora_A.default.weight, layers.10.self_attn.v_proj.lora_B.default.weight, layers.10.self_attn.o_proj.lora_A.default.weight, layers.10.self_attn.o_proj.lora_B.default.weight, layers.11.self_attn.q_proj.lora_A.default.weight, layers.11.self_attn.q_proj.lora_B.default.weight, layers.11.self_attn.k_proj.lora_A.default.weight, layers.11.self_attn.k_proj.lora_B.default.weight, layers.11.self_attn.v_proj.lora_A.default.weight, layers.11.self_attn.v_proj.lora_B.default.weight, layers.11.self_attn.o_proj.lora_A.default.weight, layers.11.self_attn.o_proj.lora_B.default.weight, layers.12.self_attn.q_proj.lora_A.default.weight, layers.12.self_attn.q_proj.lora_B.default.weight, layers.12.self_attn.k_proj.lora_A.default.weight, layers.12.self_attn.k_proj.lora_B.default.weight, layers.12.self_attn.v_proj.lora_A.default.weight, layers.12.self_attn.v_proj.lora_B.default.weight, layers.12.self_attn.o_proj.lora_A.default.weight, layers.12.self_attn.o_proj.lora_B.default.weight, layers.13.self_attn.q_proj.lora_A.default.weight, layers.13.self_attn.q_proj.lora_B.default.weight, layers.13.self_attn.k_proj.lora_A.default.weight, layers.13.self_attn.k_proj.lora_B.default.weight, layers.13.self_attn.v_proj.lora_A.default.weight, layers.13.self_attn.v_proj.lora_B.default.weight, layers.13.self_attn.o_proj.lora_A.default.weight, layers.13.self_attn.o_proj.lora_B.default.weight, layers.14.self_attn.q_proj.lora_A.default.weight, layers.14.self_attn.q_proj.lora_B.default.weight, layers.14.self_attn.k_proj.lora_A.default.weight, layers.14.self_attn.k_proj.lora_B.default.weight, layers.14.self_attn.v_proj.lora_A.default.weight, layers.14.self_attn.v_proj.lora_B.default.weight, layers.14.self_attn.o_proj.lora_A.default.weight, layers.14.self_attn.o_proj.lora_B.default.weight, layers.15.self_attn.q_proj.lora_A.default.weight, layers.15.self_attn.q_proj.lora_B.default.weight, layers.15.self_attn.k_proj.lora_A.default.weight, layers.15.self_attn.k_proj.lora_B.default.weight, layers.15.self_attn.v_proj.lora_A.default.weight, layers.15.self_attn.v_proj.lora_B.default.weight, layers.15.self_attn.o_proj.lora_A.default.weight, layers.15.self_attn.o_proj.lora_B.default.weight, layers.16.self_attn.q_proj.lora_A.default.weight, layers.16.self_attn.q_proj.lora_B.default.weight, layers.16.self_attn.k_proj.lora_A.default.weight, layers.16.self_attn.k_proj.lora_B.default.weight, layers.16.self_attn.v_proj.lora_A.default.weight, layers.16.self_attn.v_proj.lora_B.default.weight, layers.16.self_attn.o_proj.lora_A.default.weight, layers.16.self_attn.o_proj.lora_B.default.weight, layers.17.self_attn.q_proj.lora_A.default.weight, layers.17.self_attn.q_proj.lora_B.default.weight, layers.17.self_attn.k_proj.lora_A.default.weight, layers.17.self_attn.k_proj.lora_B.default.weight, layers.17.self_attn.v_proj.lora_A.default.weight, layers.17.self_attn.v_proj.lora_B.default.weight, layers.17.self_attn.o_proj.lora_A.default.weight, layers.17.self_attn.o_proj.lora_B.default.weight, layers.18.self_attn.q_proj.lora_A.default.weight, layers.18.self_attn.q_proj.lora_B.default.weight, layers.18.self_attn.k_proj.lora_A.default.weight, layers.18.self_attn.k_proj.lora_B.default.weight, layers.18.self_attn.v_proj.lora_A.default.weight, layers.18.self_attn.v_proj.lora_B.default.weight, layers.18.self_attn.o_proj.lora_A.default.weight, layers.18.self_attn.o_proj.lora_B.default.weight, layers.19.self_attn.q_proj.lora_A.default.weight, layers.19.self_attn.q_proj.lora_B.default.weight, layers.19.self_attn.k_proj.lora_A.default.weight, layers.19.self_attn.k_proj.lora_B.default.weight, layers.19.self_attn.v_proj.lora_A.default.weight, layers.19.self_attn.v_proj.lora_B.default.weight, layers.19.self_attn.o_proj.lora_A.default.weight, layers.19.self_attn.o_proj.lora_B.default.weight, layers.20.self_attn.q_proj.lora_A.default.weight, layers.20.self_attn.q_proj.lora_B.default.weight, layers.20.self_attn.k_proj.lora_A.default.weight, layers.20.self_attn.k_proj.lora_B.default.weight, layers.20.self_attn.v_proj.lora_A.default.weight, layers.20.self_attn.v_proj.lora_B.default.weight, layers.20.self_attn.o_proj.lora_A.default.weight, layers.20.self_attn.o_proj.lora_B.default.weight, layers.21.self_attn.q_proj.lora_A.default.weight, layers.21.self_attn.q_proj.lora_B.default.weight, layers.21.self_attn.k_proj.lora_A.default.weight, layers.21.self_attn.k_proj.lora_B.default.weight, layers.21.self_attn.v_proj.lora_A.default.weight, layers.21.self_attn.v_proj.lora_B.default.weight, layers.21.self_attn.o_proj.lora_A.default.weight, layers.21.self_attn.o_proj.lora_B.default.weight, layers.22.self_attn.q_proj.lora_A.default.weight, layers.22.self_attn.q_proj.lora_B.default.weight, layers.22.self_attn.k_proj.lora_A.default.weight, layers.22.self_attn.k_proj.lora_B.default.weight, layers.22.self_attn.v_proj.lora_A.default.weight, layers.22.self_attn.v_proj.lora_B.default.weight, layers.22.self_attn.o_proj.lora_A.default.weight, layers.22.self_attn.o_proj.lora_B.default.weight, layers.23.self_attn.q_proj.lora_A.default.weight, layers.23.self_attn.q_proj.lora_B.default.weight, layers.23.self_attn.k_proj.lora_A.default.weight, layers.23.self_attn.k_proj.lora_B.default.weight, layers.23.self_attn.v_proj.lora_A.default.weight, layers.23.self_attn.v_proj.lora_B.default.weight, layers.23.self_attn.o_proj.lora_A.default.weight, layers.23.self_attn.o_proj.lora_B.default.weight, layers.24.self_attn.q_proj.lora_A.default.weight, layers.24.self_attn.q_proj.lora_B.default.weight, layers.24.self_attn.k_proj.lora_A.default.weight, layers.24.self_attn.k_proj.lora_B.default.weight, layers.24.self_attn.v_proj.lora_A.default.weight, layers.24.self_attn.v_proj.lora_B.default.weight, layers.24.self_attn.o_proj.lora_A.default.weight, layers.24.self_attn.o_proj.lora_B.default.weight, layers.25.self_attn.q_proj.lora_A.default.weight, layers.25.self_attn.q_proj.lora_B.default.weight, layers.25.self_attn.k_proj.lora_A.default.weight, layers.25.self_attn.k_proj.lora_B.default.weight, layers.25.self_attn.v_proj.lora_A.default.weight, layers.25.self_attn.v_proj.lora_B.default.weight, layers.25.self_attn.o_proj.lora_A.default.weight, layers.25.self_attn.o_proj.lora_B.default.weight, layers.26.self_attn.q_proj.lora_A.default.weight, layers.26.self_attn.q_proj.lora_B.default.weight, layers.26.self_attn.k_proj.lora_A.default.weight, layers.26.self_attn.k_proj.lora_B.default.weight, layers.26.self_attn.v_proj.lora_A.default.weight, layers.26.self_attn.v_proj.lora_B.default.weight, layers.26.self_attn.o_proj.lora_A.default.weight, layers.26.self_attn.o_proj.lora_B.default.weight, layers.27.self_attn.q_proj.lora_A.default.weight, layers.27.self_attn.q_proj.lora_B.default.weight, layers.27.self_attn.k_proj.lora_A.default.weight, layers.27.self_attn.k_proj.lora_B.default.weight, layers.27.self_attn.v_proj.lora_A.default.weight, layers.27.self_attn.v_proj.lora_B.default.weight, layers.27.self_attn.o_proj.lora_A.default.weight, layers.27.self_attn.o_proj.lora_B.default.weight, layers.28.self_attn.q_proj.lora_A.default.weight, layers.28.self_attn.q_proj.lora_B.default.weight, layers.28.self_attn.k_proj.lora_A.default.weight, layers.28.self_attn.k_proj.lora_B.default.weight, layers.28.self_attn.v_proj.lora_A.default.weight, layers.28.self_attn.v_proj.lora_B.default.weight, layers.28.self_attn.o_proj.lora_A.default.weight, layers.28.self_attn.o_proj.lora_B.default.weight, layers.29.self_attn.q_proj.lora_A.default.weight, layers.29.self_attn.q_proj.lora_B.default.weight, layers.29.self_attn.k_proj.lora_A.default.weight, layers.29.self_attn.k_proj.lora_B.default.weight, layers.29.self_attn.v_proj.lora_A.default.weight, layers.29.self_attn.v_proj.lora_B.default.weight, layers.29.self_attn.o_proj.lora_A.default.weight, layers.29.self_attn.o_proj.lora_B.default.weight, layers.30.self_attn.q_proj.lora_A.default.weight, layers.30.self_attn.q_proj.lora_B.default.weight, layers.30.self_attn.k_proj.lora_A.default.weight, layers.30.self_attn.k_proj.lora_B.default.weight, layers.30.self_attn.v_proj.lora_A.default.weight, layers.30.self_attn.v_proj.lora_B.default.weight, layers.30.self_attn.o_proj.lora_A.default.weight, layers.30.self_attn.o_proj.lora_B.default.weight, layers.31.self_attn.q_proj.lora_A.default.weight, layers.31.self_attn.q_proj.lora_B.default.weight, layers.31.self_attn.k_proj.lora_A.default.weight, layers.31.self_attn.k_proj.lora_B.default.weight, layers.31.self_attn.v_proj.lora_A.default.weight, layers.31.self_attn.v_proj.lora_B.default.weight, layers.31.self_attn.o_proj.lora_A.default.weight, layers.31.self_attn.o_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"Aghori/mistral-medical-ner-qlora\", torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ff56a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MistralModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get predictions on the test set\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get the predicted and true labels\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MistralModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe804626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
