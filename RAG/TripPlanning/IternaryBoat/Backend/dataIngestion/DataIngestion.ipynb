{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fe9896-0b43-41d3-8b5e-d483f5686b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63733be1-c048-4034-ae8d-90f70fbbe2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_travel_data(data: Dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convert nested JSON to flat documents suitable for ChromaDB\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for destination, info in data.items():\n",
    "        # Create main destination document\n",
    "        main_doc = {\n",
    "            'destination': destination,\n",
    "            'best_for': ', '.join(info['BestFor']),\n",
    "            'state': info.get('State', 'N/A'),\n",
    "            'duration': info['Duration'],\n",
    "            'interests': info['BestFor'],  # Keep as list for filtering\n",
    "        }\n",
    "        \n",
    "        # Create comprehensive text for semantic search\n",
    "        itinerary_text = []\n",
    "        for day, activities in info['Iternary'].items():\n",
    "            day_activities = f\"Day {day}: \"\n",
    "            day_activities += f\"Morning - {activities.get('Morning', '')}, \"\n",
    "            day_activities += f\"Afternoon - {activities.get('Afternoon', '')}, \"\n",
    "            day_activities += f\"Evening - {activities.get('Evening', '')}\"\n",
    "            itinerary_text.append(day_activities)\n",
    "        \n",
    "        # Combine all information into searchable text\n",
    "        full_text = f\"\"\"\n",
    "        Destination: {destination}\n",
    "        State: {info.get('State', 'N/A')}\n",
    "        Best for: {', '.join(info['BestFor'])}\n",
    "        Recommended Duration: {info['Duration']} days\n",
    "        \n",
    "        Itinerary:\n",
    "        {' '.join(itinerary_text)}\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        main_doc['content'] = full_text\n",
    "        main_doc['itinerary_summary'] = ' '.join(itinerary_text)\n",
    "        \n",
    "        documents.append(main_doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f562087-a9bc-4330-8db3-a3e13c3c64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "with open('./data/Output.json', 'r') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df513d7c-9495-4d4f-8e6b-6b29149b3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = preprocess_travel_data(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d020d72-59f7-49ec-a394-f4b65e41f1ba",
   "metadata": {},
   "source": [
    "## ChromaDB Ingestion with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436d9b70-1920-464b-a0d4-1e550330dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441173ff-96c1-4f77-9dee-aeeff3744d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51dd6005-0fef-40c6-a3e2-c07445ab6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelDataIngestion:\n",
    "    def __init__(self, persist_directory=\"./chroma_travel_db\"):\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        self.persist_directory = persist_directory\n",
    "        self.vectorstore = None\n",
    "    \n",
    "    def ingest_data(self, processed_docs: List[Dict]):\n",
    "        \"\"\"\n",
    "        Ingest processed travel data into ChromaDB\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        for doc in processed_docs:\n",
    "            # Create LangChain Document with metadata\n",
    "            langchain_doc = Document(\n",
    "                page_content=doc['content'],\n",
    "                metadata={\n",
    "                    'destination': doc['destination'],\n",
    "                    'duration': doc['duration'],\n",
    "                    'state': doc['state'],\n",
    "                    'best_for': doc['best_for'],  # String for filtering\n",
    "                    'interests': ','.join(doc['interests']),  # Comma-separated\n",
    "                    'itinerary_summary': doc['itinerary_summary']\n",
    "                }\n",
    "            )\n",
    "            documents.append(langchain_doc)\n",
    "        \n",
    "        # Create ChromaDB vectorstore\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Ingested {len(documents)} destinations into ChromaDB\")\n",
    "        return self.vectorstore\n",
    "    \n",
    "    def load_existing(self):\n",
    "        \"\"\"Load existing vectorstore\"\"\"\n",
    "        self.vectorstore = Chroma(\n",
    "            persist_directory=self.persist_directory,\n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "        return self.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2929ebb8-409b-456c-a9eb-cab74c468bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amank\\AppData\\Local\\Temp\\ipykernel_17532\\636312846.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n",
      "C:\\Users\\amank\\anaconda3\\envs\\RAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingested 168 destinations into ChromaDB\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "ingestion = TravelDataIngestion()\n",
    "vectorstore = ingestion.ingest_data(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55861e20-c93f-401e-8998-240adf0c0b42",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "#### Transformation Process\n",
    "We converted nested, semi-structured JSON into flat, searchable documents with:\n",
    "- Text Content Generation: Combined all fields into a coherent, natural language paragraph\n",
    "- Metadata Extraction: Separated structured data for filtering\n",
    "- Itinerary Summarization: Flattened daily activities into searchable text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baa8ca-1760-4a4f-a55d-8d9abbae21c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
